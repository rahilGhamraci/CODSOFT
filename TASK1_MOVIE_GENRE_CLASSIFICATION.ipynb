{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n-5fiTByMfHc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from nltk.corpus import wordnet\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preparation**"
      ],
      "metadata": {
        "id": "jcMErDeKRcq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_TZXkr9My0J",
        "outputId": "d44d1b68-de19-4f13-fc79-2466288d35f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p35SxdDENJc7",
        "outputId": "9ef3e453-db08-4731-aa02-8a26802b9305"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Functions to clean the data**"
      ],
      "metadata": {
        "id": "_at47_dX-ev8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_ponctuation(word):\n",
        "    return all(caractere in string.punctuation for caractere in word)"
      ],
      "metadata": {
        "id": "e30gmNtXPfTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_multiple_white_spaces(token):\n",
        "    return all(caracter.isspace() for caracter in token)"
      ],
      "metadata": {
        "id": "r0Vfz6yRP0H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning_data(text):\n",
        "\n",
        "  tokens= word_tokenize(text)\n",
        "\n",
        "  #converting to lower case\n",
        "  tokens = [token.lower() for token in tokens]\n",
        "\n",
        "  #performing stemming\n",
        "  ps = PorterStemmer()\n",
        "  tokens = [ps.stem(token) for token in tokens]\n",
        "\n",
        "  #removing ponctuation\n",
        "  tokens = [token for token in tokens if not is_ponctuation(token)]\n",
        "\n",
        "  #removing multiple white spaces\n",
        "  tokens = [token if not is_multiple_white_spaces(token) else ' ' for token in tokens]\n",
        "\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = [token for token in tokens if token not in stop_words ]\n",
        "\n",
        "  # Reconstructing the text from tokens\n",
        "  cleaned_text = ' '.join(tokens)\n",
        "\n",
        "  return cleaned_text"
      ],
      "metadata": {
        "id": "T-YPqnKJNpLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading the data**"
      ],
      "metadata": {
        "id": "PY_bZ42QSCzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_data = pd.read_csv('train_data.txt', delimiter=':::' , header=None, engine='python')\n",
        "print(df_train_data.head())\n",
        "df_train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIaTFuK9SCYS",
        "outputId": "5fee8a2a-968c-45eb-b21a-52a093bb9cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0                                   1           2  \\\n",
            "0  1       Oscar et la dame rose (2009)       drama    \n",
            "1  2                       Cupid (1997)    thriller    \n",
            "2  3   Young, Wild and Wonderful (1980)       adult    \n",
            "3  4              The Secret Sin (1915)       drama    \n",
            "4  5             The Unrecovered (2007)       drama    \n",
            "\n",
            "                                                   3  \n",
            "0   Listening in to a conversation between his do...  \n",
            "1   A brother and sister with a past incestuous r...  \n",
            "2   As the bus empties the students for their fie...  \n",
            "3   To help their unemployed father make ends mee...  \n",
            "4   The film's title refers not only to the un-re...  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54214, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting the text description and the labels**"
      ],
      "metadata": {
        "id": "LYfImr0iaPXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xt = df_train_data.iloc[:, 3]\n",
        "Yt = df_train_data.iloc[:, 2]"
      ],
      "metadata": {
        "id": "xeKmyPVrT03K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cleaning the data**"
      ],
      "metadata": {
        "id": "zW-V4nMk-ucJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xt = [cleaning_data(text) for text in Xt]"
      ],
      "metadata": {
        "id": "sQT4oY2URNnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mapping the labels**"
      ],
      "metadata": {
        "id": "IOCurF04-4le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values = Yt.unique()\n",
        "print(unique_values)\n",
        "\n",
        "value_to_number = {value: idx for idx, value in enumerate(unique_values)}\n",
        "print(value_to_number)\n",
        "\n",
        "Yt_mapped = Yt.map(value_to_number).values.reshape(-1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzorXbgNaQYP",
        "outputId": "26d0b3d8-8810-40d9-80bb-c33c16696a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' drama ' ' thriller ' ' adult ' ' documentary ' ' comedy ' ' crime '\n",
            " ' reality-tv ' ' horror ' ' sport ' ' animation ' ' action ' ' fantasy '\n",
            " ' short ' ' sci-fi ' ' music ' ' adventure ' ' talk-show ' ' western '\n",
            " ' family ' ' mystery ' ' history ' ' news ' ' biography ' ' romance '\n",
            " ' game-show ' ' musical ' ' war ']\n",
            "{' drama ': 0, ' thriller ': 1, ' adult ': 2, ' documentary ': 3, ' comedy ': 4, ' crime ': 5, ' reality-tv ': 6, ' horror ': 7, ' sport ': 8, ' animation ': 9, ' action ': 10, ' fantasy ': 11, ' short ': 12, ' sci-fi ': 13, ' music ': 14, ' adventure ': 15, ' talk-show ': 16, ' western ': 17, ' family ': 18, ' mystery ': 19, ' history ': 20, ' news ': 21, ' biography ': 22, ' romance ': 23, ' game-show ': 24, ' musical ': 25, ' war ': 26}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the intermediate result in csv files**"
      ],
      "metadata": {
        "id": "NodL3ij3--Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "Yt_mapped_df = pd.DataFrame(Yt_mapped)\n",
        "\n",
        "Xt_df = pd.DataFrame(Xt)\n",
        "\n",
        "\n",
        "\n",
        "Yt_mapped_df.to_csv('Yt_mapped.csv', index=False, header=False)\n",
        "Xt_df.to_csv('Xt.csv', index=False, header=False)"
      ],
      "metadata": {
        "id": "k6S9S48B-2us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text representation using the TF-IDF technique**"
      ],
      "metadata": {
        "id": "N18xGcKDbiVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reload the data to continue the preprocessing**"
      ],
      "metadata": {
        "id": "eFkwM13a_l3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "Xt_df = pd.read_csv('Xt.csv', header=None)\n",
        "Xt = Xt_df.values\n",
        "Xt = [' '.join(tokens) for tokens in Xt]\n"
      ],
      "metadata": {
        "id": "GLyus4ui_hXO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting the features**"
      ],
      "metadata": {
        "id": "r8Le6v9Xal8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "\n",
        "\n",
        "n_features =10000\n",
        "v = HashingVectorizer(n_features=n_features, alternate_sign=False)\n",
        "\n",
        "\n",
        "transformed_Xt = v.transform(Xt)\n",
        "transformed_Xt = transformed_Xt.toarray()"
      ],
      "metadata": {
        "id": "74dgPI9hODNN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building the model**"
      ],
      "metadata": {
        "id": "ORwSQSA-c_5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reload the data to start the processing**"
      ],
      "metadata": {
        "id": "xjMTa0R_AY_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_Xt_df = pd.read_csv('transformed_Xt.csv', header=None)\n",
        "\n",
        "transformed_Xt = transformed_Xt_df.values"
      ],
      "metadata": {
        "id": "0QRc2LBXzNUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Yt_mapped_df = pd.read_csv('Yt_mapped.csv', header=None)\n",
        "Yt_mapped = Yt_mapped_df.values"
      ],
      "metadata": {
        "id": "iK8hLM0FznYg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "transformed_Xt, Yt_mapped = smote.fit_resample(transformed_Xt[:5000, :], Yt_mapped[:5000, :])\n",
        "\n",
        "\n",
        "transformed_Xt = np.clip(transformed_Xt, a_min=0, a_max=None)"
      ],
      "metadata": {
        "id": "lubVesNyDEzC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(transformed_Xt, Yt_mapped, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "YJ9kFBkIGid4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0],\n",
        "    'fit_prior': [True, False],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train.ravel())\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best Parameters: \", grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3kkfs9RZEAt",
        "outputId": "bcdf4ac9-bd56-4133-8f6b-0974751c1af8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters:  {'alpha': 0.3, 'fit_prior': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nb_model = MultinomialNB(alpha=0.36, fit_prior=False)\n",
        "\n",
        "\n",
        "nb_model.fit(X_train, y_train.ravel())\n",
        "\n",
        "\n",
        "y_pred = nb_model.predict(X_val)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "\n",
        "print(f'Validation Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FruTVa3uGLSd",
        "outputId": "6151f2e9-8fbf-42f8-f2c2-141f243476be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 95.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluating the model**"
      ],
      "metadata": {
        "id": "Ii2FyjNMazT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mFOQnsqIosd",
        "outputId": "45dcb6f8-1551-4696-b9ac-66a10917727a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.57      0.61       231\n",
            "           1       0.88      0.99      0.93       246\n",
            "           2       0.99      1.00      0.99       237\n",
            "           3       0.79      0.78      0.79       250\n",
            "           4       0.83      0.76      0.79       262\n",
            "           5       1.00      1.00      1.00       272\n",
            "           6       0.99      1.00      0.99       243\n",
            "           7       0.92      1.00      0.95       245\n",
            "           8       0.99      1.00      0.99       271\n",
            "           9       0.99      1.00      1.00       241\n",
            "          10       0.96      0.98      0.97       268\n",
            "          11       1.00      1.00      1.00       259\n",
            "          12       0.88      0.71      0.79       270\n",
            "          13       0.97      1.00      0.99       233\n",
            "          14       0.99      1.00      0.99       249\n",
            "          15       0.98      1.00      0.99       248\n",
            "          16       0.98      1.00      0.99       231\n",
            "          17       0.98      1.00      0.99       270\n",
            "          18       0.99      1.00      0.99       216\n",
            "          19       1.00      1.00      1.00       274\n",
            "          20       0.99      1.00      1.00       247\n",
            "          21       1.00      1.00      1.00       248\n",
            "          22       1.00      1.00      1.00       257\n",
            "          23       0.96      1.00      0.98       264\n",
            "          24       1.00      1.00      1.00       257\n",
            "          25       1.00      1.00      1.00       245\n",
            "          26       1.00      1.00      1.00       227\n",
            "\n",
            "    accuracy                           0.95      6761\n",
            "   macro avg       0.95      0.95      0.95      6761\n",
            "weighted avg       0.95      0.95      0.95      6761\n",
            "\n"
          ]
        }
      ]
    }
  ]
}